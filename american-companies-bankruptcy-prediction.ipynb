{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# American companies Bankruptcy prediction","metadata":{}},{"cell_type":"markdown","source":"| Variable Name          | Description                                               |\n|------------------------|-----------------------------------------------------------|\n| X1                     | Current assets: All assets expected to be sold or used   |\n|                        | in standard business operations over the next year       |\n| X2                     | Cost of goods sold: Total cost directly related to the   |\n|                        | sale of products                                          |\n| X3                     | Depreciation and amortization: Loss of value of         |\n|                        | tangible and intangible assets over time                 |\n| X4                     | EBITDA: Earnings before interest, taxes, depreciation,   |\n|                        | and amortization; alternative measure of financial      |\n|                        | performance compared to net income                        |\n| X5                     | Inventory: Accounting of items and raw materials used   |\n|                        | in production or for sale                                 |\n| X6                     | Net Income: Overall profitability after deducting       |\n|                        | expenses and costs from total revenue                     |\n| X7                     | Total Receivables: Balance of money due for delivered   |\n|                        | goods or services not yet paid by customers              |\n| X8                     | Market value: Asset price in the marketplace, in this    |\n|                        | case, market capitalization since companies are publicly|\n|                        | traded in the stock market                                |\n| X9                     | Net sales: Gross sales minus returns, allowances, and   |\n|                        | discounts                                                  |\n| X10                    | Total assets: All items of value owned by a business     |\n| X11                    | Total Long term debt: Loans and liabilities not due     |\n|                        | within one year of the balance sheet date                |\n| X12                    | EBIT: Earnings before interest and taxes                 |\n| X13                    | Gross Profit: Profit after subtracting costs related     |\n|                        | to manufacturing and selling products or services        |\n| X14                    | Total Current Liabilities: Sum of accounts payable,      |\n|                        | accrued liabilities, taxes, and bonds payable at year end|\n| X15                    | Retained Earnings: Profit left after paying costs,       |\n|                        | taxes, and dividends to shareholders                      |\n| X16                    | Total Revenue: Total income from sales before expenses   |\n| X17                    | Total Liabilities: Combined debts and obligations owed   |\n|                        | to external parties                                       |\n| X18                    | Total Operating Expenses: Business operation expenses    |\n| year                   | Year                                                     |\n| status_label           | Bank Status: Failed or Alive (Target column)             |","metadata":{}},{"cell_type":"markdown","source":"# Importing necessary libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve, mean_squared_error, r2_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.exceptions import ConvergenceWarning\nimport warnings\nwarnings.filterwarnings('ignore', category=ConvergenceWarning)","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-10-01T10:34:50.259186Z","iopub.execute_input":"2023-10-01T10:34:50.259843Z","iopub.status.idle":"2023-10-01T10:34:52.792339Z","shell.execute_reply.started":"2023-10-01T10:34:50.259810Z","shell.execute_reply":"2023-10-01T10:34:52.790936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"df= pd.read_csv('/kaggle/input/american-companies-bankruptcy-prediction-dataset/american_bankruptcy.csv')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-10-01T10:34:52.794971Z","iopub.execute_input":"2023-10-01T10:34:52.795460Z","iopub.status.idle":"2023-10-01T10:34:53.329267Z","shell.execute_reply.started":"2023-10-01T10:34:52.795415Z","shell.execute_reply":"2023-10-01T10:34:53.327313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory data analysis (EDA)","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:34:53.330806Z","iopub.execute_input":"2023-10-01T10:34:53.331595Z","iopub.status.idle":"2023-10-01T10:34:53.388286Z","shell.execute_reply.started":"2023-10-01T10:34:53.331555Z","shell.execute_reply":"2023-10-01T10:34:53.386784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary statistics","metadata":{}},{"cell_type":"code","source":"def summary(df):\n    print(f'data shape: {df.shape}')  \n    summ = pd.DataFrame(df.dtypes, columns=['data type'])\n    summ['#missing'] = df.isnull().sum().values \n    summ['%missing'] = df.isnull().sum().values / len(df)* 100\n    summ['#unique'] = df.nunique().values\n    desc = pd.DataFrame(df.describe(include='all').transpose())\n    summ['min'] = desc['min'].values\n    summ['max'] = desc['max'].values\n    summ['first value'] = df.loc[0].values\n    summ['second value'] = df.loc[1].values\n    summ['third value'] = df.loc[2].values\n\n    return summ\n\nsummary(df)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-10-01T10:34:53.391854Z","iopub.execute_input":"2023-10-01T10:34:53.392751Z","iopub.status.idle":"2023-10-01T10:34:53.749436Z","shell.execute_reply.started":"2023-10-01T10:34:53.392706Z","shell.execute_reply":"2023-10-01T10:34:53.748200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_summary_as_image(df, filename):\n    # Create the summary table\n    summary = pd.DataFrame(df.dtypes, columns=['data type'])\n    summary['#missing'] = df.isnull().sum().values \n    summary['%missing'] = df.isnull().sum().values / len(df)* 100\n    summary['#unique'] = df.nunique().values\n    desc = pd.DataFrame(df.describe(include='all').transpose())\n    summary['min'] = desc['min'].values\n    summary['max'] = desc['max'].values\n    summary['first value'] = df.loc[0].values\n    summary['second value'] = df.loc[1].values\n    summary['third value'] = df.loc[2].values\n\n    # Create a figure and axis\n    fig, ax = plt.subplots(figsize=(10, 6))\n\n    # Remove axes for cleaner visualization\n    ax.axis('off')\n\n    # Plot the table\n    table = ax.table(cellText=summary.values, colLabels=summary.columns, cellLoc='center', loc='center')\n\n    # Style the table\n    table.auto_set_font_size(False)\n    table.set_fontsize(10)\n    table.scale(1.2, 1.2)\n\n    # Save the figure as a PNG image\n    plt.savefig(filename, bbox_inches='tight', dpi=300)\n    plt.close()\n\n# Call the function to save the summary table as an image\nsave_summary_as_image(df, 'summary_table.png')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:34:53.750775Z","iopub.execute_input":"2023-10-01T10:34:53.751398Z","iopub.status.idle":"2023-10-01T10:34:56.004261Z","shell.execute_reply.started":"2023-10-01T10:34:53.751352Z","shell.execute_reply":"2023-10-01T10:34:56.002944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to the summary, the US Company Bankruptcy DataFrame has 78,682 rows and 21 columns. Here's how the data was analysed:\n\n1. **Data Types:** The DataFrame contains columns with various data types, such as `object`, `int64`, and `float64`.\n\n2. **Missing Values:** There are no missing values in any of the columns as indicated by the `%missing` column showing 0.0% missing values for all columns.\n\n3. **Unique Values:** The number of unique values for each column varies. For instance, `company_name` has 8,971 unique values, `status_label` has 2 unique values, and other columns have different numbers of unique values.\n\n4. **Summary Statistics:** The `describe` function provides statistical summary for numerical columns. It includes count, mean, standard deviation, minimum, 25th percentile (Q1), median (50th percentile or Q2), 75th percentile (Q3), and maximum values.\n\n5. **Example Values:** The DataFrame displays the first three values for each column under the columns `first value`, `second value`, and `third value`. For instance, `company_name` has the values 'C_1', 'C_1', and 'C_1' for the first three rows.(Companies' names are coded for security reasons.)\n","metadata":{}},{"cell_type":"markdown","source":"# Target Column Distribution","metadata":{}},{"cell_type":"code","source":"alive_count = df['status_label'].value_counts()['alive']\nfailed_count = df['status_label'].value_counts()['failed']\ntotal_count = alive_count + failed_count\nalive_ratio = alive_count / total_count\nfailed_ratio = failed_count / total_count\n\nprint(\"Alive Ratio:\", alive_ratio)\nprint(\"Failed Ratio:\", failed_ratio)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:34:56.006292Z","iopub.execute_input":"2023-10-01T10:34:56.007435Z","iopub.status.idle":"2023-10-01T10:34:56.031604Z","shell.execute_reply.started":"2023-10-01T10:34:56.007390Z","shell.execute_reply":"2023-10-01T10:34:56.030334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Given counts and ratios\nalive_count = df['status_label'].value_counts()['alive']\nfailed_count = df['status_label'].value_counts()['failed']\ntotal_count = alive_count + failed_count\nalive_ratio = alive_count / total_count\nfailed_ratio = failed_count / total_count\n\n# Data for the pie chart\nlabels = ['Alive', 'Failed']\nsizes = [alive_ratio, failed_ratio]\ncolors = ['green', 'red']\nexplode = (0.1, 0)  # Explode the first slice\n\n# Create a pie chart\nplt.figure(figsize=(6, 6))\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\nplt.axis('equal')  # Equal aspect ratio ensures the pie chart is circular\n\n# Save the pie chart as a PNG image\nplt.savefig('pie_chart.png', bbox_inches='tight', dpi=300)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:34:56.032827Z","iopub.execute_input":"2023-10-01T10:34:56.033298Z","iopub.status.idle":"2023-10-01T10:34:56.549795Z","shell.execute_reply.started":"2023-10-01T10:34:56.033269Z","shell.execute_reply":"2023-10-01T10:34:56.548265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The \"Alive Ratio\" is approximately **0.934**, which means that around **93.4%** of the samples in the dataset belong to the \"alive\" class (e.g., companies that have not failed or gone bankrupt).\n\n- The \"Failed Ratio\" is approximately **0.066**, which means that only about **6.6% of** the samples in the dataset belong to the \"failed\" class (e.g., companies that have experienced bankruptcy or failure).\n\nThis significant class imbalance can have implications for building predictive models. When the dataset is **highly imbalanced**, models may be biased towards the majority class (in this case, \"alive\") and may not perform well in identifying the minority class (in this case, \"failed\").\n\nTo address this issue, you may consider employing techniques such as:\n\n- **Class Balancing Techniques:** Using methods like oversampling the minority class (e.g., Synthetic Minority Over-sampling Technique - SMOTE) or undersampling the majority class to balance the class distribution.\n\n- **Different Evaluation Metrics:** Instead of accuracy, consider using evaluation metrics like precision, recall, F1-score, or area under the ROC curve (AUC), which are more suitable for imbalanced datasets.\n\n- **Algorithm Selection:** Choose algorithms that are less sensitive to class imbalance, such as ensemble methods (e.g., Random Forest, Gradient Boosting) or anomaly detection methods.\n\n- **Cost-sensitive Learning:** Assigning different misclassification costs for each class during model training to reflect the importance of correctly predicting the minority class.","metadata":{}},{"cell_type":"markdown","source":"## Outliers","metadata":{}},{"cell_type":"code","source":"Q1 = df[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18']].quantile(0.25)\nQ3 = df[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18']].quantile(0.75)\nIQR = Q3 - Q1\noutliers = ((df[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18']] < (Q1 - 1.5 * IQR)) | (df[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18']] > (Q3 + 1.5 * IQR)))\n\nplt.figure(figsize=(12, 8))\nsns.boxplot(data=df[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18']])\nplt.xticks(rotation=90)\nplt.title(\"Box Plot of Numerical Features with Outliers\")\nplt.xlabel(\"Features\")\nplt.ylabel(\"Values\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:34:56.551528Z","iopub.execute_input":"2023-10-01T10:34:56.552220Z","iopub.status.idle":"2023-10-01T10:34:57.663685Z","shell.execute_reply.started":"2023-10-01T10:34:56.552180Z","shell.execute_reply":"2023-10-01T10:34:57.662506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well Thats alot!!! Dealing with outliers is crucial to ensure that they do not adversely affect the performance of your predictive models. Outliers can skew the distribution of data and impact the model's ability to generalize to unseen data. Here are some strategies to handle outliers in your dataset:\n\n- Remove Outliers: One straightforward approach is to remove the outliers from the dataset. However, this should be done with caution, as outliers may contain valuable information or represent rare but significant events. Removing too many outliers can lead to loss of important data.\n- Outlier Detection Models: Use outlier detection algorithms (e.g., Isolation Forest, One-Class SVM) to identify and mark outliers. You can then choose whether to remove them or treat them separately during analysis.\n- Transform Data: Instead of removing outliers, you can apply data transformations to reduce their impact. Common transformations include log-transform, square-root transform, or Box-Cox transform. These transformations can make the data more normally distributed and reduce the effect of extreme values.","metadata":{}},{"cell_type":"markdown","source":"## Correlation Matrix","metadata":{}},{"cell_type":"code","source":"variables = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18']\ndata = df[variables]\ncorrelation_matrix = data.corr()\nmask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5, mask=mask)\nplt.title('Correlation Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:34:57.665412Z","iopub.execute_input":"2023-10-01T10:34:57.665868Z","iopub.status.idle":"2023-10-01T10:34:58.771173Z","shell.execute_reply.started":"2023-10-01T10:34:57.665828Z","shell.execute_reply":"2023-10-01T10:34:58.770229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:34:58.774180Z","iopub.execute_input":"2023-10-01T10:34:58.774552Z","iopub.status.idle":"2023-10-01T10:34:58.804402Z","shell.execute_reply.started":"2023-10-01T10:34:58.774522Z","shell.execute_reply":"2023-10-01T10:34:58.803046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"variables = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18']\ndata = df[variables]\ncorrelation_matrix = data.corr()\ncorrelation_matrix","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:34:58.806117Z","iopub.execute_input":"2023-10-01T10:34:58.806597Z","iopub.status.idle":"2023-10-01T10:34:58.920084Z","shell.execute_reply.started":"2023-10-01T10:34:58.806550Z","shell.execute_reply":"2023-10-01T10:34:58.918758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nvariables = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18']\ndata = df[variables]\ncorrelation_matrix = data.corr()\nmask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5, mask=mask)\nplt.title('Correlation Matrix')\n\n# Save the heatmap as an image\nplt.savefig('correlation_heatmap.png', bbox_inches='tight', dpi=300)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:34:58.921508Z","iopub.execute_input":"2023-10-01T10:34:58.922113Z","iopub.status.idle":"2023-10-01T10:35:01.201472Z","shell.execute_reply.started":"2023-10-01T10:34:58.922070Z","shell.execute_reply":"2023-10-01T10:35:01.199925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-Processing","metadata":{}},{"cell_type":"code","source":"df['status_label'] = df['status_label'].map({'alive': 1, 'failed': 0})\nX = df.drop(columns=['company_name', 'status_label'])\ny = df['status_label']","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:35:01.204024Z","iopub.execute_input":"2023-10-01T10:35:01.204553Z","iopub.status.idle":"2023-10-01T10:35:01.227348Z","shell.execute_reply.started":"2023-10-01T10:35:01.204501Z","shell.execute_reply":"2023-10-01T10:35:01.225773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Convert the categorical target variable 'status_label' to numerical labels (1 for 'alive' and 0 for 'failed').\n- Create the feature matrix X, excluding the 'company_name' and 'status_label' columns, to be used for training the machine learning model.\n- Set the target variable y as the numerical 'status_label', representing the labels for the training dataset.\n\nAfter these preprocessing steps, you can proceed with model training using X as the feature matrix and y as the target variable.","metadata":{}},{"cell_type":"markdown","source":"# Features Selection","metadata":{}},{"cell_type":"markdown","source":"# Using LogisticRegression and RandomForestRegressor","metadata":{}},{"cell_type":"markdown","source":"We are performing feature selection using two different algorithms: Logistic Regression and Random Forests. The goal of feature selection is to identify a subset of relevant features from the original dataset that will be used for model training. By selecting only the most important features, we aim to reduce the complexity of the model, improve its performance, and potentially avoid overfitting.","metadata":{}},{"cell_type":"code","source":"logit_model = LogisticRegression()\n\nlogit_model.fit(X, y)\nlogit_feature_importances = pd.Series(logit_model.coef_[0], index=X.columns).abs()\nselected_features_logit = logit_feature_importances.nlargest(10).index.tolist()\n\nrf_model = RandomForestClassifier()\n\nrf_model.fit(X, y)\nrf_feature_importances = pd.Series(rf_model.feature_importances_, index=X.columns).abs()\nselected_features_rf = rf_feature_importances.nlargest(10).index.tolist()\n\ndf_logit_selected = df[['company_name', 'status_label'] + selected_features_logit]\ndf_rf_selected = df[['company_name', 'status_label'] + selected_features_rf]\nprint(\"Selected features using logistic regression:\", selected_features_logit)\nprint(\"Selected features using random forests:\", selected_features_rf)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:35:01.229111Z","iopub.execute_input":"2023-10-01T10:35:01.229496Z","iopub.status.idle":"2023-10-01T10:35:52.158890Z","shell.execute_reply.started":"2023-10-01T10:35:01.229431Z","shell.execute_reply":"2023-10-01T10:35:52.157794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_features_logit = ['year', 'X5', 'X1', 'X14', 'X12', 'X3', 'X8', 'X7', 'X17', 'X11']\nselected_features_rf = ['X8', 'X15', 'X3', 'X1', 'X17', 'X7', 'X13', 'X10', 'X14', 'X6']\n\ndf_logit_selected = df[['status_label'] + selected_features_logit]\ndf_rf_selected = df[['status_label'] + selected_features_rf]\n\nprint(\"New dataset with selected features from logistic regression:\")\nprint(df_logit_selected.head())\n\nprint(\"\\nNew dataset with selected features from random forests:\")\nprint(df_rf_selected.head())\n\ndf_logit_selected.to_csv('logit_selected_features_dataset.csv', index=False)\ndf_rf_selected.to_csv('rf_selected_features_dataset.csv', index=False)\n\nprint(\"Datasets saved to CSV files.\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:35:52.160352Z","iopub.execute_input":"2023-10-01T10:35:52.160864Z","iopub.status.idle":"2023-10-01T10:35:53.520347Z","shell.execute_reply.started":"2023-10-01T10:35:52.160825Z","shell.execute_reply":"2023-10-01T10:35:53.519611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_rf_selected.shape, df_logit_selected.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:35:53.521442Z","iopub.execute_input":"2023-10-01T10:35:53.522385Z","iopub.status.idle":"2023-10-01T10:35:53.527799Z","shell.execute_reply.started":"2023-10-01T10:35:53.522354Z","shell.execute_reply":"2023-10-01T10:35:53.526578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"markdown","source":"# RandomForestClassifier","metadata":{}},{"cell_type":"code","source":"X_rf = df_rf_selected.drop('status_label', axis=1)\ny_rf = df_rf_selected['status_label']\n\nX_rf_train, X_rf_test, y_rf_train, y_rf_test = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)\nrf_model = RandomForestClassifier(random_state=42)\nrf_model.fit(X_rf_train, y_rf_train)\ny_rf_pred = rf_model.predict(X_rf_test)\nrf_accuracy = accuracy_score(y_rf_test, y_rf_pred)\nprint(\"Random Forest Accuracy: {:.2f}%\".format(rf_accuracy * 100))\n\n# Confusion Matrix\ncm = confusion_matrix(y_rf_test, y_rf_pred)\nprint(\"Confusion Matrix:\")\nprint(cm)\n\n# Plot Confusion Matrix as a Heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=0.5, square=True)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Classification Report\ncr = classification_report(y_rf_test, y_rf_pred)\nprint(\"Classification Report:\")\nprint(cr)\n\n# ROC Curve and AUC-ROC\ny_rf_scores = rf_model.predict_proba(X_rf_test)[:, 1]\nfpr, tpr, thresholds = roc_curve(y_rf_test, y_rf_scores)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.show()\n\n# Precision-Recall Curve\nprecision, recall, thresholds_pr = precision_recall_curve(y_rf_test, y_rf_scores)\n\nplt.figure(figsize=(8, 6))\nplt.plot(recall, precision, color='blue', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.grid(True)\nplt.show()\n\n#Cross-Validation Scores\ncv_scores = cross_val_score(rf_model, X_rf, y_rf, cv=5)\nprint(\"\\nCross-Validation Scores:\")\nfor i, score in enumerate(cv_scores):\n    print(\"Fold {}: {:.2f}%\".format(i + 1, score * 100))\n\n# Average Cross-Validation Score\naverage_cv_score = cv_scores.mean()\nprint(\"Average Cross-Validation Score: {:.2f}%\".format(average_cv_score * 100))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:35:53.528890Z","iopub.execute_input":"2023-10-01T10:35:53.529171Z","iopub.status.idle":"2023-10-01T10:39:16.663246Z","shell.execute_reply.started":"2023-10-01T10:35:53.529147Z","shell.execute_reply":"2023-10-01T10:39:16.661320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=0.5, square=True)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.savefig('confusion_matrix.png', bbox_inches='tight', dpi=300)\nplt.show()\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.savefig('roc_curve.png', bbox_inches='tight', dpi=300)\nplt.show()\n\n\nplt.figure(figsize=(8, 6))\nplt.plot(recall, precision, color='blue', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.grid(True)\nplt.savefig('precision_recall_curve.png', bbox_inches='tight', dpi=300)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:39:16.665247Z","iopub.execute_input":"2023-10-01T10:39:16.665649Z","iopub.status.idle":"2023-10-01T10:39:19.183604Z","shell.execute_reply.started":"2023-10-01T10:39:16.665615Z","shell.execute_reply":"2023-10-01T10:39:19.181985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Support Vector Machine (SVM)","metadata":{}},{"cell_type":"code","source":"X_rf = df_rf_selected.drop('status_label', axis=1)\ny_rf = df_rf_selected['status_label']\n\nX_rf_train, X_rf_test, y_rf_train, y_rf_test = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)\n\nsvm_model = SVC(random_state=42)\nsvm_model.fit(X_rf_train, y_rf_train)\ny_rf_pred = svm_model.predict(X_rf_test)\n\nsvm_accuracy = accuracy_score(y_rf_test, y_rf_pred)\nprint(\"SVM Accuracy: {:.2f}%\".format(svm_accuracy * 100))\n\n# Confusion Matrix\ncm_svm = confusion_matrix(y_rf_test, y_rf_pred)\nprint(\"Confusion Matrix:\")\nprint(cm_svm)\n\n# Classification Report\ncr_svm = classification_report(y_rf_test, y_rf_pred)\nprint(\"Classification Report:\")\nprint(cr_svm)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:39:19.185265Z","iopub.execute_input":"2023-10-01T10:39:19.185849Z","iopub.status.idle":"2023-10-01T10:40:05.433140Z","shell.execute_reply.started":"2023-10-01T10:39:19.185816Z","shell.execute_reply":"2023-10-01T10:40:05.431756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DecisionTreeClassifier","metadata":{}},{"cell_type":"code","source":"X_logit = df_logit_selected.drop('status_label', axis=1)\ny_logit = df_logit_selected['status_label']\nX_logit_train, X_logit_test, y_logit_train, y_logit_test = train_test_split(X_logit, y_logit, test_size=0.2, random_state=42)\n\ndt_model = DecisionTreeClassifier(random_state=42)\ndt_model.fit(X_logit_train, y_logit_train)\n\ny_logit_pred = dt_model.predict(X_logit_test)\n\ndt_accuracy = accuracy_score(y_logit_test, y_logit_pred)\nprint(\"Decision Tree Accuracy: {:.2f}%\".format(dt_accuracy * 100))\n\n# Confusion Matrix\ncm_dt = confusion_matrix(y_logit_test, y_logit_pred)\nprint(\"Confusion Matrix:\")\nprint(cm_dt)\n\n# Classification Report\ncr_dt = classification_report(y_logit_test, y_logit_pred)\nprint(\"Classification Report:\")\nprint(cr_dt)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:40:05.435163Z","iopub.execute_input":"2023-10-01T10:40:05.436090Z","iopub.status.idle":"2023-10-01T10:40:06.826454Z","shell.execute_reply.started":"2023-10-01T10:40:05.436046Z","shell.execute_reply":"2023-10-01T10:40:06.825145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameters tuning using Grid Search","metadata":{}},{"cell_type":"code","source":"param_grid = {\n    'max_depth': [None, 5, 10, 15],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'criterion': ['gini', 'entropy']\n}\n\ndt_tuned = DecisionTreeClassifier(random_state=42)\ngrid_search = GridSearchCV(dt_tuned, param_grid, cv=5)\ngrid_search.fit(X_logit_train, y_logit_train)\n\nbest_dt_model = grid_search.best_estimator_\nbest_dt_pred = best_dt_model.predict(X_logit_test)\nbest_dt_accuracy = accuracy_score(y_logit_test, best_dt_pred)\nprint(\"Best Decision Tree Accuracy: {:.2f}%\".format(best_dt_accuracy * 100))\n\n# Confusion Matrix\ncm_dt = confusion_matrix(y_logit_test, best_dt_pred)\nprint(\"Confusion Matrix:\")\nprint(cm_dt)\n\n# Classification Report\ncr_dt = classification_report(y_logit_test, best_dt_pred)\nprint(\"Classification Report:\")\nprint(cr_dt)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:40:06.828358Z","iopub.execute_input":"2023-10-01T10:40:06.829489Z","iopub.status.idle":"2023-10-01T10:44:47.683255Z","shell.execute_reply.started":"2023-10-01T10:40:06.829441Z","shell.execute_reply":"2023-10-01T10:44:47.682175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## xgboost","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Splitting the data\nX_xgb = df_rf_selected.drop('status_label', axis=1)\ny_xgb = df_rf_selected['status_label']\nX_xgb_train, X_xgb_test, y_xgb_train, y_xgb_test = train_test_split(X_xgb, y_xgb, test_size=0.2, random_state=42)\n\n\nlabel_encoder = LabelEncoder()\ny_xgb_train = label_encoder.fit_transform(y_xgb_train)\ny_xgb_test = label_encoder.transform(y_xgb_test)\ny_xgb_encoded = label_encoder.transform(y_xgb)\n\n# Create XGBoost model\nxgb_model = xgb.XGBClassifier(random_state=42)\nxgb_model.fit(X_xgb_train, y_xgb_train)\n\n# Predictions\ny_xgb_pred = xgb_model.predict(X_xgb_test)\n\n# Accuracy\nxgb_accuracy = accuracy_score(y_xgb_test, y_xgb_pred)\nprint(\"XGBoost Accuracy: {:.2f}%\".format(xgb_accuracy * 100))\n\n# Confusion Matrix\ncm_xgb = confusion_matrix(y_xgb_test, y_xgb_pred)\nprint(\"Confusion Matrix:\")\nprint(cm_xgb)\n\n# Classification Report\ncr_xgb = classification_report(y_xgb_test, y_xgb_pred)\nprint(\"Classification Report:\")\nprint(cr_xgb)\n\n# ROC Curve and AUC-ROC\ny_xgb_scores = xgb_model.predict_proba(X_xgb_test)[:, 1]\nfpr_xgb, tpr_xgb, thresholds_xgb = roc_curve(y_xgb_test, y_xgb_scores)\nroc_auc_xgb = auc(fpr_xgb, tpr_xgb)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr_xgb, tpr_xgb, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_xgb))\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.show()\nplt.savefig('xgb_roc_curve.png', bbox_inches='tight', dpi=300)\nplt.show()\n\n\n# Precision-Recall Curve\nprecision_xgb, recall_xgb, thresholds_pr_xgb = precision_recall_curve(y_xgb_test, y_xgb_scores)\n\nplt.figure(figsize=(8, 6))\nplt.plot(recall_xgb, precision_xgb, color='blue', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.grid(True)\nplt.show()\nplt.savefig('xgb_precision_recall_curve.png', bbox_inches='tight', dpi=300)\nplt.show()\n\n# Cross-Validation Scores\ncv_scores_xgb = cross_val_score(xgb_model, X_xgb, y_xgb_encoded, cv=5)\nprint(\"\\nCross-Validation Scores:\")\nfor i, score in enumerate(cv_scores_xgb):\n    print(\"Fold {}: {:.2f}%\".format(i + 1, score * 100))\n\n# Average Cross-Validation Score\naverage_cv_score_xgb = cv_scores_xgb.mean()\nprint(\"Average Cross-Validation Score: {:.2f}%\".format(average_cv_score_xgb * 100))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:44:47.684622Z","iopub.execute_input":"2023-10-01T10:44:47.684989Z","iopub.status.idle":"2023-10-01T10:45:39.350709Z","shell.execute_reply.started":"2023-10-01T10:44:47.684962Z","shell.execute_reply":"2023-10-01T10:45:39.349623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_xgb_scores = xgb_model.predict_proba(X_xgb_test)[:, 1]\nfpr_xgb, tpr_xgb, thresholds_xgb = roc_curve(y_xgb_test, y_xgb_scores)\nroc_auc_xgb = auc(fpr_xgb, tpr_xgb)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr_xgb, tpr_xgb, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc_xgb))\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.savefig('xgb_roc_curve.png', bbox_inches='tight', dpi=300)  # Save before showing\nplt.show()\n\n# Precision-Recall Curve\nprecision_xgb, recall_xgb, thresholds_pr_xgb = precision_recall_curve(y_xgb_test, y_xgb_scores)\n\nplt.figure(figsize=(8, 6))\nplt.plot(recall_xgb, precision_xgb, color='blue', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.grid(True)\nplt.savefig('xgb_precision_recall_curve.png', bbox_inches='tight', dpi=300)  # Save before showing\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:45:39.355449Z","iopub.execute_input":"2023-10-01T10:45:39.357911Z","iopub.status.idle":"2023-10-01T10:45:40.815812Z","shell.execute_reply.started":"2023-10-01T10:45:39.357864Z","shell.execute_reply":"2023-10-01T10:45:40.814725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GradientBoostingClassifier","metadata":{}},{"cell_type":"code","source":"X_rf_train, X_rf_test, y_rf_train, y_rf_test = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)\ngb_model = GradientBoostingClassifier(random_state=42)\ngb_model.fit(X_rf_train, y_rf_train)\ny_gb_pred = gb_model.predict(X_rf_test)\n\n# Calculate accuracy\ngb_accuracy = accuracy_score(y_rf_test, y_gb_pred)\nprint(\"Gradient Boosting Accuracy: {:.2f}%\".format(gb_accuracy * 100))\n\n# Confusion Matrix\ncm_gb = confusion_matrix(y_rf_test, y_gb_pred)\nprint(\"Confusion Matrix:\")\nprint(cm_gb)\n\n# Classification Report\ncr_gb = classification_report(y_rf_test, y_gb_pred)\nprint(\"Classification Report:\")\nprint(cr_gb)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:45:40.817349Z","iopub.execute_input":"2023-10-01T10:45:40.817768Z","iopub.status.idle":"2023-10-01T10:46:12.065650Z","shell.execute_reply.started":"2023-10-01T10:45:40.817732Z","shell.execute_reply":"2023-10-01T10:46:12.064585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, f1_score","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:46:12.067058Z","iopub.execute_input":"2023-10-01T10:46:12.067472Z","iopub.status.idle":"2023-10-01T10:46:12.072818Z","shell.execute_reply.started":"2023-10-01T10:46:12.067443Z","shell.execute_reply":"2023-10-01T10:46:12.071652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_rf_pred = svm_model.predict(X_rf_test)\n\n# Get decision function scores for SVM\ny_svm_scores = svm_model.decision_function(X_rf_test)\n\n# Calculate ROC AUC for SVM\nroc_auc_svm = roc_auc_score(y_rf_test, y_svm_scores)\n\n# Calculate F1 Score for SVM\nf1_score_svm = f1_score(y_rf_test, y_rf_pred)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:46:12.074188Z","iopub.execute_input":"2023-10-01T10:46:12.074610Z","iopub.status.idle":"2023-10-01T10:46:29.122875Z","shell.execute_reply.started":"2023-10-01T10:46:12.074573Z","shell.execute_reply":"2023-10-01T10:46:29.121646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_scores_svm = cross_val_score(best_dt_model, X_rf, y_rf, cv=5)\naverage_cv_score_svm = cv_scores_svm.mean()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:46:29.123786Z","iopub.execute_input":"2023-10-01T10:46:29.124118Z","iopub.status.idle":"2023-10-01T10:46:31.655213Z","shell.execute_reply.started":"2023-10-01T10:46:29.124094Z","shell.execute_reply":"2023-10-01T10:46:31.653850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate ROC AUC for Decision Tree\nroc_auc_dt = roc_auc_score(y_logit_test, best_dt_pred)\n\n# Calculate F1 Score for Decision Tree\nf1_score_dt = f1_score(y_logit_test, best_dt_pred)\n\n# Calculate Cross-Validation Scores for Decision Tree using the same data and model from Random Forest\ncv_scores_dt = cross_val_score(best_dt_model, X_rf, y_rf, cv=5)\naverage_cv_score_dt = cv_scores_dt.mean()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:46:31.659315Z","iopub.execute_input":"2023-10-01T10:46:31.659924Z","iopub.status.idle":"2023-10-01T10:46:34.209960Z","shell.execute_reply.started":"2023-10-01T10:46:31.659896Z","shell.execute_reply":"2023-10-01T10:46:34.208996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate ROC AUC for Gradient Boosting\nroc_auc_gb = roc_auc_score(y_rf_test, y_gb_pred)\n\n# Calculate F1 Score for Gradient Boosting\nf1_score_gb = f1_score(y_rf_test, y_gb_pred)\n\n# Calculate Cross-Validation Scores for Gradient Boosting\ncv_scores_gb = cross_val_score(gb_model, X_rf, y_rf, cv=5)\naverage_cv_score_gb = cv_scores_gb.mean()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:46:34.211140Z","iopub.execute_input":"2023-10-01T10:46:34.212245Z","iopub.status.idle":"2023-10-01T10:49:09.168492Z","shell.execute_reply.started":"2023-10-01T10:46:34.212211Z","shell.execute_reply":"2023-10-01T10:49:09.167230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_rf_pred = rf_model.predict(X_rf_test)\ny_rf_true = y_rf_test  # Replace with your true labels\n\n# Calculate F1 Score for Random Forest\nf1_score_rf = f1_score(y_rf_true, y_rf_pred)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:49:09.169976Z","iopub.execute_input":"2023-10-01T10:49:09.170329Z","iopub.status.idle":"2023-10-01T10:49:09.556170Z","shell.execute_reply.started":"2023-10-01T10:49:09.170300Z","shell.execute_reply":"2023-10-01T10:49:09.555382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score_rf = f1_score(y_rf_test, y_gb_pred)\nf1_score_xgb = f1_score(y_rf_test, y_rf_pred)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:49:09.557394Z","iopub.execute_input":"2023-10-01T10:49:09.558311Z","iopub.status.idle":"2023-10-01T10:49:09.577778Z","shell.execute_reply.started":"2023-10-01T10:49:09.558281Z","shell.execute_reply":"2023-10-01T10:49:09.576580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Create a dictionary to store the model names and their respective metrics\nmodel_metrics = {\n    'Model': ['RandomForest', 'SVM', 'DecisionTree', 'XGBoost', 'GradientBoosting'],\n    'Accuracy': [rf_accuracy, svm_accuracy, dt_accuracy, xgb_accuracy, gb_accuracy],\n    'ROC AUC': [roc_auc, roc_auc_svm, roc_auc_dt, roc_auc_xgb, roc_auc_gb],\n    'F1 Score': [f1_score_rf, f1_score_svm, f1_score_dt, f1_score_xgb, f1_score_gb],\n    'Cross-Validation Score': [average_cv_score, average_cv_score_svm, average_cv_score_dt, average_cv_score_xgb, average_cv_score_gb]\n}\n\n# Create a DataFrame from the dictionary\nsummary_df = pd.DataFrame(model_metrics)\n\n# Display the summary table\nprint(summary_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:49:09.579832Z","iopub.execute_input":"2023-10-01T10:49:09.580548Z","iopub.status.idle":"2023-10-01T10:49:09.592888Z","shell.execute_reply.started":"2023-10-01T10:49:09.580508Z","shell.execute_reply":"2023-10-01T10:49:09.591466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n# Create a DataFrame with your model metrics\nmodel_metrics = {\n    'Model': ['RandomForest', 'SVM', 'DecisionTree', 'XGBoost', 'GradientBoosting'],\n    'Accuracy': [rf_accuracy, svm_accuracy, dt_accuracy, xgb_accuracy, gb_accuracy],\n    'ROC AUC': [roc_auc, roc_auc_svm, roc_auc_dt, roc_auc_xgb, roc_auc_gb],\n    'F1 Score': [f1_score_rf, f1_score_svm, f1_score_dt, f1_score_xgb, f1_score_gb],\n}\n\nsummary_df = pd.DataFrame(model_metrics)\n\n# Set the style of the plot to white background with no grid lines\nsns.set(style=\"white\", rc={\"axes.grid\": False})\n\n# Create a bar plot for Accuracy\nplt.figure(figsize=(8, 5))\nsns.barplot(x='Model', y='Accuracy', data=summary_df, palette=\"Blues_d\")\nplt.title('Accuracy Comparison')\n\n# Save the plot as an image\nplt.savefig('accuracy_comparison.png', bbox_inches='tight', dpi=300)\n\n# Show the plot\nplt.show()\n\n# Create a bar plot for ROC AUC\nplt.figure(figsize=(8, 5))\nsns.barplot(x='Model', y='ROC AUC', data=summary_df, palette=\"Blues_d\")\nplt.title('ROC AUC Comparison')\n\n# Save the plot as an image\nplt.savefig('roc_auc_comparison.png', bbox_inches='tight', dpi=300)\n\n# Show the plot\nplt.show()\n\n# Create a bar plot for F1 Score\nplt.figure(figsize=(8, 5))\nsns.barplot(x='Model', y='F1 Score', data=summary_df, palette=\"Blues_d\")\nplt.title('F1 Score Comparison')\n\n# Save the plot as an image\nplt.savefig('f1_score_comparison.png', bbox_inches='tight', dpi=300)\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:56:20.043945Z","iopub.execute_input":"2023-10-01T10:56:20.044357Z","iopub.status.idle":"2023-10-01T10:56:21.978197Z","shell.execute_reply.started":"2023-10-01T10:56:20.044328Z","shell.execute_reply":"2023-10-01T10:56:21.976889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# # Create a DataFrame with your model metrics\n# model_metrics = {\n#     'Model': ['RandomForest', 'SVM', 'DecisionTree', 'XGBoost', 'GradientBoosting'],\n#     'Accuracy': [rf_accuracy, svm_accuracy, dt_accuracy, xgb_accuracy, gb_accuracy],\n#     'ROC AUC': [roc_auc, roc_auc_svm, roc_auc_dt, roc_auc_xgb, roc_auc_gb],\n#     'F1 Score': [f1_score_rf, f1_score_svm, f1_score_dt, f1_score_xgb, f1_score_gb],\n# }\n\n# summary_df = pd.DataFrame(model_metrics)\n\n# # Set the style of the plot\n# sns.set(style=\"whitegrid\")\n\n# # Create a bar plot for Accuracy\n# plt.figure(figsize=(8, 5))\n# sns.barplot(x='Model', y='Accuracy', data=summary_df)\n# plt.title('Accuracy Comparison')\n\n# # Save the plot as an image\n# plt.savefig('accuracy_comparison.png', bbox_inches='tight')\n\n# # Show the plot\n# plt.show()\n\n# # Create a bar plot for ROC AUC\n# plt.figure(figsize=(8, 5))\n# sns.barplot(x='Model', y='ROC AUC', data=summary_df)\n# plt.title('ROC AUC Comparison')\n\n# # Save the plot as an image\n# plt.savefig('roc_auc_comparison.png', bbox_inches='tight')\n\n# # Show the plot\n# plt.show()\n\n# # Create a bar plot for F1 Score\n# plt.figure(figsize=(8, 5))\n# sns.barplot(x='Model', y='F1 Score', data=summary_df)\n# plt.title('F1 Score Comparison')\n\n# # Save the plot as an image\n# plt.savefig('f1_score_comparison.png', bbox_inches='tight')\n\n# # Show the plot\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T10:49:11.689010Z","iopub.execute_input":"2023-10-01T10:49:11.689305Z","iopub.status.idle":"2023-10-01T10:49:11.694989Z","shell.execute_reply.started":"2023-10-01T10:49:11.689272Z","shell.execute_reply":"2023-10-01T10:49:11.693869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}